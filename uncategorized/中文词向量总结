<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="google-site-verification" content="z3UrryM2397YOnoqdKnrWKwdswdo3Es-0HxaBNqlLLM">













  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css">


  <meta name="keywords" content="Hexo, NexT">





  <link rel="alternate" href="/atom.xml" title="Devin Kuang's Blog" type="application/atom+xml">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2">






<meta name="description" content="中文词向量总结词向量基础知识 one-hot编码：假设我们的词库总共有n个词，那我们开一个1*n的高维向量，而每个词都会在某个索引index下取到1，其余位置全部都取值为0.词向量在这种类型的编码中如下图所示：">
<meta name="keywords" content="个人博客">
<meta property="og:type" content="article">
<meta property="og:title" content="中文词向量总结">
<meta property="og:url" content="http://yoursite.com/uncategorized/中文词向量总结">
<meta property="og:site_name" content="Devin Kuang&#39;s Blog">
<meta property="og:description" content="中文词向量总结词向量基础知识 one-hot编码：假设我们的词库总共有n个词，那我们开一个1*n的高维向量，而每个词都会在某个索引index下取到1，其余位置全部都取值为0.词向量在这种类型的编码中如下图所示：">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="d:/Desktop/hexo/source/images/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/TIM%E6%88%AA%E5%9B%BE20180816002842.png">
<meta property="og:image" content="d:/Desktop/hexo/source/images/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534386200978.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/TIM%E6%88%AA%E5%9B%BE20180816002958.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534386256334.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534386268566.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534386449294.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534386546469.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534386564568.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534402886692.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534404827474.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534406106531.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534408796031.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534409069724.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534409092996.png">
<meta property="og:image" content="d:/%E5%B7%A5%E4%BD%9C/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E8%AE%AD%E7%BB%83/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534427551903.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534427631389.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534427748594.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534421197938.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534421237285.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534421279834.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534424804682.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534423427445.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534423506380.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534424995665.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534425097746.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534425165032.png">
<meta property="og:image" content="d:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534426032178.png">
<meta property="og:updated_time" content="2018-10-31T16:30:26.906Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="中文词向量总结">
<meta name="twitter:description" content="中文词向量总结词向量基础知识 one-hot编码：假设我们的词库总共有n个词，那我们开一个1*n的高维向量，而每个词都会在某个索引index下取到1，其余位置全部都取值为0.词向量在这种类型的编码中如下图所示：">
<meta name="twitter:image" content="d:/Desktop/hexo/source/images/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/TIM%E6%88%AA%E5%9B%BE20180816002842.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/uncategorized/中文词向量总结">





  <title>中文词向量总结 | Devin Kuang's Blog</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?c9eac00a42028265df4e527542204520";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>










</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Devin Kuang's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">谁终将声震人间, 必长久深自缄默; 谁终将点燃闪电, 必长久如云漂泊.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于我
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            时间线
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/uncategorized/中文词向量总结">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Devin Kuang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Devin Kuang's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">中文词向量总结</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-10-31T21:06:54+08:00">
                2018-10-31
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/uncategorized/中文词向量总结#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="uncategorized/中文词向量总结" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/uncategorized/中文词向量总结" class="leancloud_visitors" data-flag-title="中文词向量总结">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计</span>
                
                <span title="字数统计">
                  5,968 字
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长</span>
                
                <span title="阅读时长">
                  22 分钟
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="中文词向量总结"><a href="#中文词向量总结" class="headerlink" title="中文词向量总结"></a>中文词向量总结</h1><h2 id="词向量基础知识"><a href="#词向量基础知识" class="headerlink" title="词向量基础知识"></a>词向量基础知识</h2><ul>
<li>one-hot编码：假设我们的词库总共有n个词，那我们开一个1*n的高维向量，而每个词都会在某个索引index下取到1，其余位置全部都取值为0.词向量在这种类型的编码中如下图所示：</li>
</ul>
<a id="more"></a>
<p><img src="D:/Desktop/hexo/source/images/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/TIM%E6%88%AA%E5%9B%BE20180816002842.png" alt="TIM截图20180816002842"></p>
<p>这种词向量编码方式简单粗暴，我们将每一个词作为一个完全独立的个体来表达。遗憾的是，这种方式下，我们的词向量没办法给我们任何形式的词组相似性权衡（任何两个one-hot向量内积都为0），而且每个词向量都高维稀疏,高维稀疏会造成维度灾难,计算复杂,存储量大等问题</p>
<ul>
<li><p>基于SVD的方法：首先会遍历所有的文本数据集，然后统计词出现的次数，接着用一个矩阵$X$来表示所有的次数情况，紧接着对X进行奇异值分解得到一个$USV^T$的分解。然后用$U$的行（rows）作为所有词表中词的词向量,其中矩阵$X$的构建可以采用基于窗口的共现矩阵或者词-文档矩阵。基于SVD的方法能够充分地编码语义和句法的信息，但同时也带来了其他的问题：</p>
<ul>
<li>矩阵的维度会经常变化（新的词语经常会增加，语料库的大小也会随时变化）。</li>
<li>矩阵是非常稀疏的，因为大多数词并不同时出现。</li>
<li>矩阵的维度通常非常高（≈$10^6*10^6$）</li>
<li>训练需要$O(n^2)$的复杂度（比如SVD）</li>
<li>需要专门对矩阵X进行特殊处理，以应对词组频率的极度不平衡的状况</li>
</ul>
</li>
<li><p>基于迭代的方法：我们并不计算和存储全局信息，因为这会包含太多大型数据集和数十亿句子。我们尝试创建一个模型，它能够一步步迭代地进行学习，并最终得出每个单词基于其上下文的条件概率。在每次迭代过程中，这个模型都能够评估其误差，并按照一定的更新规则，惩罚那些导致误差的参数</p>
<ul>
<li><p>连续词袋模型（CBOM）</p>
<p>有种模型是以{“The”, “cat”, ’over”, “the’, “puddle”}为上下文，能够预测或产生它们中心的词语”jumped”，叫做连续词袋模型,模型如图所示：</p>
<p><img src="D:/Desktop/hexo/source/images/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534386200978.png" alt="1534386200978"></p>
<p>模型的运作方式如下：</p>
<ol>
<li>对于m个词长度的输入上下文，我们产生它们的one-hot向量<img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/TIM%E6%88%AA%E5%9B%BE20180816002958.png" alt="TIM截图20180816002958"></li>
<li>我们得到上下文的嵌入词向量<img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534386256334.png" alt="1534386256334"></li>
<li>将这些向量取平均<img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534386268566.png" alt="1534386268566"></li>
<li>产生一个得分向量 $z=U\hat{v}$</li>
<li>将得分向量转换成概率分布形式$\hat{y}=softmax(z)$</li>
<li>我们希望我们产生的概率分布 ,与真实概率分布$y$相匹配。而刚好也就是我们期望$y$的真实词语的one-hot向量</li>
<li>利用交叉熵做为损失函数，最小化损失函数更新权重</li>
</ol>
<p>要注意我们实际上对于每个词语$w_i$学习了两个向量。（作为输入词的向量$v_i$，和作为输出词的向量$u_j$） </p>
</li>
<li><p>Skip-Gram 模型</p>
<p>跟上面提到的模型对应的另一种思路，是以中心的词语”jumped”为输入，能够预测或产生它周围的词语”The”, “cat”, ’over”, “the”, “puddle”等。这里我们叫”jumped”为上下文。我们把它叫做Skip-Gram 模型。 这个模型的建立与连续词袋模型（CBOM）非常相似，但本质上是交换了输入和输出的位置。我们令输入的one-hot向量（中心词）为x（因为它只有一个），输出向量为y(j)。U和V的定义与连续词袋模型一样，模型如图所示：</p>
<p><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534386449294.png" alt="1534386449294"></p>
<p>模型的运行方式如下：</p>
<ol>
<li>生成one-hot输入向量x。</li>
<li>得到上下文的嵌入词向量$v_c=Vx$。</li>
<li>因为这里不需要取平均值的操作，所以直接是$\hat{v}=v_c$。</li>
<li>通过$u=Uv_c$产生2m个得分向量<img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534386546469.png" alt="1534386546469">。</li>
<li>将得分向量转换成概率分布形式$y=softmax(u)$。</li>
<li>我们希望我们产生的概率分布与真实概率分布<img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534386564568.png" alt="1534386564568">相匹配，也就是我们真实输出结果的one-hot向量。</li>
<li>利用交叉熵做为损失函数，最小化损失函数更新权重</li>
</ol>
</li>
<li><p>负面抽样（Negative Sampling）</p>
<ul>
<li><p>思路对比:</p>
<ul>
<li>Softmax：所有词(类别)当成单个词(类别)处理(有V个分类)</li>
<li>H-softmax ：部分词(类别)当成负类处理(二叉树遍历时非叶子节点负例对应的子孙叶子节点)(有logV个分类)</li>
<li>负采样： 正类当成单个处理，非正类的词(类别)当成负类处理,为了减少计算量,负类里面做抽样)(有2个分类)</li>
</ul>
</li>
<li><p>相同点: 负采样和h-softmax一样，采用LR做节点上的分类</p>
</li>
<li><p>两个问题:</p>
<ul>
<li><p>1个正例和neg个负例如何做LR?</p>
</li>
<li><p>如何进行负采样?</p>
<p>word2vec采样的方法并不复杂，如果词汇表的大小为]$V$那么我们就将一段长度为1的线段分成$V$份，每份对应词汇表中的一个词。当然每个词对应的线段长度是不一样的，高频词对应的线段长，低频词对应的线段短。每个词$w$的线段长度由下式决定 :</p>
<p><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534402886692.png" alt="1534402886692"></p>
<p>取3/4的原因：抑制太高频的词, 提升太低频的词 </p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>层次softmax</p>
<ul>
<li>目的: 解决softmax每次训练更新都需要对所有预测类别(词)做指数计算,计算量过大的问题</li>
<li>实现:<ul>
<li>采用霍夫曼编码根据类别(词)出现频率构建二叉树</li>
<li>二叉树的叶子节点是要预测的类别(词)</li>
<li>非叶子节点可以当做是神经网络的神经元,每个节点都有对应的输入和参数</li>
</ul>
</li>
<li>为何能节省计算(以中心词w2为例):<ul>
<li>Softmax(需要计算O1、O2…Ov做指数计算,复杂度O(V)</li>
<li>h-softmax(最大似然w2出现的概率,只要计算root-w2路径上的概率乘积,复杂度O(logV)词向量训练</li>
</ul>
</li>
<li>层次softmax只是在训练的时候可以减少计算，在预测的时候，因为事先并不知道真实的输出分类，还是要计算所有输出，得到概率最大的输出 </li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="使用gensim训练词向量"><a href="#使用gensim训练词向量" class="headerlink" title="使用gensim训练词向量"></a>使用gensim训练词向量</h2><ul>
<li><p><a href="https://radimrehurek.com/gensim/models/word2vec.html" target="_blank" rel="noopener">gensim</a>介绍:一款开源的第三方Python工具包，支持包括TF-IDF，LSA，LDA，和word2vec等算法接口 </p>
</li>
<li><p>gensim安装:gensim安装要注意，gensim包依赖numpy和scipy包，可以去官网看gensim包依赖的最低numpy和scipy版本，然后<code>pip install gensim</code>,最简单的方式就是先安装anaconda,然后安装gensim，而且也要注意版本，具体可以参考 <a href="https://blog.csdn.net/hereiskxm/article/details/49424799" target="_blank" rel="noopener">gensim安装</a>，如果安装成功，<code>from gensim.models import word2vec</code>不会报错</p>
</li>
<li><p>gensim训练词向量步骤:</p>
<ul>
<li><p>数据来源:资讯新闻数据(hive 表 t_sd_safe_news_source_kb),通过命令:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive -e &quot;select content_html from t_sd_safe_news_source_kb where ds = 20180815 and category1 =  &apos;ent&apos; &quot; &gt; news_ent_content_html.txt</span><br></pre></td></tr></table></figure>
<p>注意编码问题(通过这种方式导入的编码方式是GBK编码,可以通过python脚本将编码方式转换为utf-8,方便以后的计算),得到的文本格式如下:</p>
<p><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534404827474.png" alt="1534404827474"></p>
<p>一行代表一条html格式的资讯</p>
</li>
<li><p>数据预处理:提取正文,中文分词,参考代码<code>/data/ceph_ai/devinkuang/code/Preprocessing.py</code>,代码支持并行化分词(LTP+NER),处理html文件,去除停止词,去除标点.</p>
<p>注意:</p>
<ul>
<li><p>训练词向量的时候不需要去除停止词和标点,因为词向量的训练是根据窗口共现的方式,停止词和标点也是句子成分的一部分</p>
</li>
<li><p>对原始数据预处理会出现很多问题,例如原始数据出现utf-8不能编码的字符;一条资讯内部出现换行符(会导致html解析错误);资讯全是图片,解析后没有文字等</p>
</li>
<li><p>使用opencc-python繁体转简体、jieba中文分词</p>
<p>可以opencc-python包，或者直接下载exe执行文件，使用命令<code>opencc -i wiki-zh-article.txt -o wiki-zh-article-zhs.txt -c t2s.json</code>接下来就是做分词，比较好用的工具有<a href="https://github.com/fxsjy/jieba" target="_blank" rel="noopener">结巴分词</a>、<a href="http://ictclas.nlpir.org/" target="_blank" rel="noopener">中科院的ICTCLAS</a>、<a href="http://thulac.thunlp.org/" target="_blank" rel="noopener">清华的THULAC</a>、<a href="https://github.com/FudanNLP/fnlp" target="_blank" rel="noopener">复旦的FudanNLP</a>等。我选用了结巴 </p>
<p>问题：之前是在代码里面使用opencc-python繁体转简体（而且是按照空格对文章切分之后，一个一个转换）发现速度很慢，后来选择使用exe执行文件，执行速度很快</p>
</li>
</ul>
<p>处理后,得到如下格式的文本:</p>
<p><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534406106531.png" alt="1534406106531"></p>
</li>
<li><p>使用gensim提供的接口实现Word2vec训练:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> Word2Vec</span><br><span class="line"><span class="keyword">from</span> gensim.models.word2vec <span class="keyword">import</span> LineSentence</span><br><span class="line"><span class="comment"># LineSentence(source, max_sentence_length=10000, limit=None)</span></span><br><span class="line">inp = <span class="string">'news_ent_content.txt'</span> <span class="comment"># 训练数据,一行一条资讯</span></span><br><span class="line">outp1 = <span class="string">'news-ent-cbow-model'</span> <span class="comment"># 保存模型的参数和词向量</span></span><br><span class="line">outp2 = <span class="string">'news-ent-cbow-vector'</span> <span class="comment"># 保存词向量的结果</span></span><br><span class="line"></span><br><span class="line">model = Word2Vec(LineSentence(inp), size = <span class="number">400</span>, window = <span class="number">5</span>, min_count = <span class="number">5</span>, workers = multiprocessing.cpu_count()) <span class="comment">## 参数都是按照常用的参数</span></span><br><span class="line"></span><br><span class="line">model.save(outp1) <span class="comment">## 以二进制格式存储</span></span><br><span class="line">model.save_word2vec_format(outp2, binary = <span class="keyword">False</span>) <span class="comment">## 以文本格式存储， 一行是一个词的vector</span></span><br></pre></td></tr></table></figure>
<p>词向量有很多参数,如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">1) sentences: 我们要分析的语料，可以是一个列表，或者从文件中遍历读出。后面我们会有从文件读出的例子。</span><br><span class="line"></span><br><span class="line">2) size: 词向量的维度，默认值是100。这个维度的取值一般与我们的语料的大小相关，如果是不大的语料，比如小于100M的文本语料，则使用默认值一般就可以了。如果是超大的语料，建议增大维度。size对词向量的影响很大,如果维度特别低或特别高，精度就会比较低 低维度词向量无法捕捉文集中不同词语的不同意义。这可以视为我们模型复杂度过低而导致的高偏差。比如 “king”, “queen”, “man”, “woman” 这几个词，我们需要至少2个维度像”gender” 如 “leadership” 来把它们编译成 2-字节 词向量。 过低的维度将无法捕捉四个词之间的语义差别，而过高的维度将捕捉到一些对泛化能力没有用的噪音– 即高方差的问题</span><br><span class="line"></span><br><span class="line">3) window：即词向量上下文最大距离，这个参数在我们的算法原理篇中标记为c，window越大，则和某一词较远的词也会产生上下文关系。默认值为5。在实际使用中，可以根据实际的需求来动态调整这个window的大小。如果是小语料则这个值可以设的更小。对于一般的语料这个值推荐在[5,10]之间。Skip-gram通常选择10左右，CBOW通常选择5左右(从博客上看到的，尚未找到理由，所以别信)</span><br><span class="line"></span><br><span class="line">4) sg: 即我们的word2vec两个模型的选择了。如果是0， 则是CBOW模型，是1,则是Skip-Gram模型，默认是0即CBOW模型。</span><br><span class="line"></span><br><span class="line">5) hs: 即我们的word2vec两个解法的选择了，如果是0， 则是Negative Sampling，是1的话并且负采样个数negative大于0， 则是Hierarchical Softmax。默认是0即Negative Sampling。</span><br><span class="line"></span><br><span class="line">6) negative:即使用Negative Sampling时负采样的个数，默认是5。推荐在[3,10]之间。这个参数在我们的算法原理篇中标记为neg。论文中设置的参数是10</span><br><span class="line"></span><br><span class="line">7) cbow_mean: 仅用于CBOW在做投影的时候，为0，则算法中的xw为上下文的词向量之和，为1则为上下文的词向量的平均值。在我们的原理篇中，是按照词向量的平均值来描述的。个人比较喜欢用平均值来表示xw,默认值也是1,不推荐修改默认值。</span><br><span class="line"></span><br><span class="line">8) min_count:需要计算词向量的最小词频。这个值可以去掉一些很生僻的低频词，默认是5。如果是小语料，可以调低这个值。这个值的设定也可以过滤一些分词错误的词</span><br><span class="line"></span><br><span class="line">9) iter: 随机梯度下降法中迭代的最大次数，默认是5。对于大语料，可以增大这个值。</span><br><span class="line"></span><br><span class="line">10) alpha: 在随机梯度下降法中迭代的初始步长。算法原理篇中标记为η，默认是0.025。</span><br><span class="line"></span><br><span class="line">11) min_alpha: 由于算法支持在迭代的过程中逐渐减小步长，min_alpha给出了最小的迭代步长值。随机梯度下降中每轮的迭代步长可以由iter，alpha， min_alpha一起得出。这部分由于不是word2vec算法的核心内容，因此在原理篇我们没有提到。对于大语料，需要对alpha, min_alpha,iter一起调参，来选择合适的三个值。</span><br></pre></td></tr></table></figure>
<p>参数的设置,一是设置经验参数,二是通过词向量评估的方法评估词向量,然后调整参数</p>
<p>词向量训练完成后,会得到四个文件:</p>
<p><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534408796031.png" alt="1534408796031"></p>
<p>我们可以通过gensim提供的方法对词向量训练出来的结果进行测试,常见的包括类比推理和相似性测试,测试链接<a href="http://jupyter233.wsd.oa.com/notebooks/devinkuang/test_for_word2vec_ent.ipynb" target="_blank" rel="noopener">:word2vec_ent测试</a>,展示一些结果:</p>
<p><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534409069724.png" alt="1534409069724"></p>
<p><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534409092996.png" alt="1534409092996"></p>
</li>
<li><p>词向量的增量训练:gensim中word2vec提供增量训练的方式,如果有新加的词汇,可以在原有的模型上继续训练,具体如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 增量训练</span></span><br><span class="line">model = gensim.models.Word2Vec.load(temp_path) <span class="comment"># 加载原来的模型</span></span><br><span class="line">more_sentences = [[<span class="string">'Advanced'</span>, <span class="string">'users'</span>, <span class="string">'can'</span>, <span class="string">'load'</span>, <span class="string">'a'</span>, <span class="string">'model'</span>, <span class="string">'and'</span>, <span class="string">'continue'</span>, <span class="string">'training'</span>, <span class="string">'it'</span>, <span class="string">'with'</span>, <span class="string">'more'</span>, <span class="string">'sentences'</span>]] <span class="comment"># 需要增量学习的语料</span></span><br><span class="line">model.build_vocab(more_sentences, update=<span class="keyword">True</span>) <span class="comment"># 对词表的词汇更新</span></span><br><span class="line">model.train(more_sentences, total_examples=model.corpus_count, epochs=model.iter) <span class="comment"># 增量学习</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">train(sentences, total_examples=None, total_words=None, epochs=None, start_alpha=None, end_alpha=None, word_count=0, queue_factor=2, report_delay=1.0, compute_loss=False, callbacks=())</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>所有相关的代码,数据和模型在<a href="mailto:mqq@100.65.21.223" target="_blank" rel="noopener">mqq@100.65.21.223</a>: /data/ceph_ai/devinkuang目录下</p>
<p>数据:</p>
<p><img src="D:/%E5%B7%A5%E4%BD%9C/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E8%AE%AD%E7%BB%83/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534427551903.png" alt="1534427551903"></p>
</li>
</ul>
<p>模型:</p>
<p><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534427631389.png" alt="1534427631389"></p>
<p>代码:</p>
<p><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534427748594.png" alt="1534427748594"></p>
<h2 id="词向量评价"><a href="#词向量评价" class="headerlink" title="词向量评价"></a>词向量评价</h2><ul>
<li><p>内部任务评价</p>
<p>外部任务评价是对在实际任务中产生的词向量进行的评价。这些任务通常是很复杂的，且它们的计算过程比较缓慢。在我们前面使用的例子中，允许基于问题对答案进行评估的系统是一种外部任务评价系统。一般来讲， 优化外部评价系统的时候我们无从知晓是哪个子系统除了问题，所以需要进一步进行内部任务评价 ,常见方法:</p>
<ul>
<li>词聚类：可以采用 kmeans 聚类，看聚类簇的分布</li>
<li>词cos 相关性：查找cos相近的词</li>
<li>Analogy对比：a:b 与 c:d的cos距离 (man-king woman-queen )</li>
<li>使用tnse，pca等降维可视化展示：词的分布，推荐用google的<a href="https://www.tensorflow.org/guide/summaries_and_tensorboard" target="_blank" rel="noopener">tensorboard</a>，可以多视角查看，如果不想搭建服务，直接访问<a href="http://projector.tensorflow.org/" target="_blank" rel="noopener">这里</a>。另外可以用python的matplotlib</li>
</ul>
</li>
<li><p>外部任务评价</p>
<p>外部任务评价是对在实际任务中产生的词向量进行的评价。这些任务通常是很复杂的，且它们的计算过程比较缓慢。在我们前面使用的例子中，允许基于问题对答案进行评估的系统是一种外部任务评价系统。一般来讲， 优化外部评价系统的时候我们无从知晓是哪个子系统出了问题，所以需要进一步进行内部任务评价 </p>
</li>
<li><p>对外在性任务进行训练</p>
<ul>
<li><p>重训练词向量</p>
<p>先初始化一个词向量,然后根据外部具体的任务对词向量进行fine-tune(TextCNN中的no-static就用了这个方法),不过，重训练词向量是由风险的,如果要在外部任务上重新训练词向量，我们需要保证训练集的大小足够覆盖词库中的大多数单词。因为Word2Vec或GloVe 生成的语义相关的词会在词空间中落在同一部分位置。如果我们用一个比较小的训练集去重训练，这些词在词空间中的位置就会发生变化，在最终任务上的精确度反而可能降低 ,因此，如果训练集较小，则最好不要重训练词向量。如果训练集很大，重训练也许能够提升精度 </p>
</li>
</ul>
</li>
<li><p>词向量内部评价实践</p>
<ul>
<li><p>评测数据集:</p>
<ul>
<li><p>CA-translated数据集:其中大多数类比问题直接从英语基准中翻译得到 ,在很多中文词嵌入的论文被广泛应用</p>
<p><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534421197938.png" alt="1534421197938"></p>
</li>
<li><p>CA8:CA8 是专门为中文语言设计的。它包含了 17813 个类比问题，覆盖了综合的词法和语义关联 </p>
<p>semantic.txt:</p>
<p><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534421237285.png" alt="1534421237285"></p>
<p>morphological.txt:</p>
<p><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534421279834.png" alt="1534421279834"></p>
</li>
<li><p>下载地址和详情<a href="https://github.com/Embedding/Chinese-Word-Vectors/tree/master/testsets" target="_blank" rel="noopener">https://github.com/Embedding/Chinese-Word-Vectors/tree/master/testsets</a></p>
</li>
</ul>
</li>
<li><p>测评代码在/data/ceph_ai/devinkuang/evaluate_word2vec/evaluation,运行:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ python ana_eval_dense.py -v &lt;vector.txt&gt; -a CA8/morphological.txt</span><br><span class="line">$ python ana_eval_dense.py -v &lt;vector.txt&gt; -a CA8/semantic.txt</span><br></pre></td></tr></table></figure>
<p>既可以对自己得到的词向量文件vector.txt测试效果,下面我测试一下用维基百科数据训练Word2vec的测试结果,参数:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = Word2Vec(LineSentence(rawdata), size=<span class="number">400</span>, window=<span class="number">5</span>, min_count=<span class="number">5</span>, workers=multiprocessing.cpu_count())</span><br></pre></td></tr></table></figure>
<p><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534424804682.png" alt="1534424804682"></p>
<p>以上结果据目前最好的结果还有不小的差距</p>
</li>
</ul>
</li>
<li><p>通过测评我们会发现,影响词向量的主要有一下几个因素:</p>
<ul>
<li><p>语料的影响:</p>
<p>不同的语料训练的词向量的结果差别很大,比如,我用娱乐类资讯的结果,查看苹果的top10相似词:<br><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534423427445.png" alt="1534423425701"></p>
<p>而用所以得资讯训练的结果如下:</p>
<p><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534423506380.png" alt="1534423506380"></p>
<p>词向量存在的一个最大的问题是,同样的词只有一种词向量的表达方式,不能处理多义性,Huang等人（2012）在论文《Improving Word Representations Via Global Context And Multiple Word Prototypes》中描述了如何在自然语言处理中解决上面提到的问题。他们提出的方法本质在于以下几点 </p>
<ol>
<li>针对目标单词出现的所有位置，收集固定大小的语境窗口（例如，此单词之前的5个单词至此单词之后的5个单词）</li>
<li>用上下文中词向量的加权平均(用idf-weighting)来表示每段上下文(当前语境) 。</li>
<li>应用球面k均值算法对第二步中的结果进行聚类。</li>
<li>最后，每一次的单词出现都被重新标签成它所属的类，并且针对这个类，来训练相对应的词向量</li>
</ol>
<p>当然文集量越大，精度越高 ,这是因为，例子越多，生成的系统学习到的经验就更丰富。比如在完成词汇类比的例子中，系统如果之前没有接触测试词，就可能会生成错误的结果 </p>
</li>
<li><p>算法参数的影响:主要影响模型的参数是:语言模型(skip-gram,cbow),窗口大小,向量维度,negative,min-cout等,推荐设置的大小参考参数介绍的内容</p>
</li>
<li><p>训练速度的影响因素:lword2vec 影响速度的因素：语言模型(cbow更快)、迭代次数、线程数等</p>
</li>
</ul>
</li>
<li><p>关于词向量相关评测的论文:Analogical Reasoning on Chinese Morphological and Semantic Relations  2018 ACL,项目链接：<a href="https://github.com/Embedding/Chinese-Word-Vectors" target="_blank" rel="noopener">https://github.com/Embedding/Chinese-Word-Vectors</a> </p>
<p>该项目提供使用不同表征（稀疏和密集）、上下文特征（单词、n-gram、字符等）以及语料库训练的中文词向量（嵌入）。在这里，你可以轻松获得具有不同属性的预训练向量，并将它们用于各类下游任务。</p>
<p>此外，开发者还在该工具中提供了一个中文类比推理数据集 CA8 及其评估工具包，用户可以以此评估自己词向量的质量。</p>
<p>参数设置如下:</p>
<p><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534424995665.png" alt="1534424995665"></p>
<p>百度百科数据,评测不同表征（稀疏和密集）、上下文特征（单词、n-gram、字符等）的结果:</p>
<p><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534425097746.png" alt="1534425097746"></p>
<p>SNGS模型,不同数据的影响:</p>
<p><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534425165032.png" alt="1534425165032"></p>
</li>
</ul>
<h2 id="最新研究"><a href="#最新研究" class="headerlink" title="最新研究"></a>最新研究</h2><ul>
<li><p><a href="https://github.com/facebookresearch/fastText" target="_blank" rel="noopener">FastText</a></p>
<ul>
<li>模型如下:</li>
</ul>
<p><img src="D:/Desktop/hexo/source/%E4%B8%AD%E6%96%87%E8%AF%8D%E5%90%91%E9%87%8F%E6%80%BB%E7%BB%93.assets/1534426032178.png" alt="1534426032178"></p>
<p>fastText 模型输入一个词的序列（一段文本或者一句话)，输出这个词序列属于不同类别的概率。  序列中的词和词组组成特征向量，特征向量通过线性变换映射到中间层，中间层再映射到标签。  fastText 在预测标签时使用了非线性激活函数，但在中间层不使用非线性激活函数。  fastText 模型架构和 Word2Vec 中的 CBOW 模型很类似。不同之处在于，fastText 预测标签，而 CBOW 模型预测中间词 </p>
<ul>
<li>fastText和word2vec CBOW的区别与联系:<ul>
<li>目的:<ol>
<li>Fasttext-文本整段输入来预测分类(没有窗口的概念)</li>
<li>Word2vec-上下文来预测中间词</li>
</ol>
</li>
<li>监督or无监督:<ol>
<li>Fasttext是有监督-需要人工分类打标</li>
<li>word2vec无监督-不需要打标</li>
</ol>
</li>
<li>输入:<ol>
<li>Fasttext 没有one-hot,直接是embedded,同时采用了n-gram</li>
</ol>
</li>
<li>加速训练方法和word2vec类似,都用了层次softmax和负采样</li>
</ul>
</li>
<li>fastText词向量的优势<ul>
<li>速度快:适合大型数据+高效的训练速度：能够训练模型“在使用标准多核CPU的情况下10分钟内处理超过10亿个词汇”，特别是与深度模型对比，fastText能将训练时间由数天缩短到几秒钟 </li>
<li>加入了n-gram特征,利用了语言形态结构 ,使得在用于像捷克语这样词态丰富的语言时，这种方式表现得非常好 </li>
<li>比word2vec更考虑了相似性，比如 fastText 的词嵌入学习能够考虑 english-born 和 british-born 之间有相同的后缀，但 word2vec 却不能 </li>
<li>fastText专注于文本分类，在许多标准问题上实现当下最好的表现 </li>
</ul>
</li>
</ul>
</li>
<li><p><a href="https://nlp.stanford.edu/projects/glove/" target="_blank" rel="noopener">Glove</a></p>
<ol>
<li>glove模型背景:考虑到Cbow/Skip-Gram 是一个local context window的方法，比如使用NS来训练，缺乏了整体的词和词的关系，负样本采用sample的方式会缺失词的关系信息。 另外，直接训练Skip-Gram类型的算法，很容易使得高曝光词汇得到过多的权重。</li>
<li>Global Vector融合了矩阵分解Latent Semantic Analysis (LSA)的全局统计信息和local context window优势。融入全局的先验统计信息，可以加快模型的训练速度，又可以控制词的相对权重。</li>
<li>模型目标：进行词的向量化表示，使得向量之间尽可能多地蕴含语义和语法的信息。输入：语料库输出：词向量方法概述：首先基于语料库构建词的共现矩阵，然后基于共现矩阵和GloVe模型学习词向量。 开始 -&gt; 统计共现矩阵 -&gt; 训练词向量 -&gt; 结束</li>
<li>GloVe在多义词方面表现出色 </li>
</ol>
</li>
<li><p><a href="https://arxiv.org/pdf/1506.02761v3.pdf" target="_blank" rel="noopener">WordRank: Learning Word Embeddings via Robust </a> </p>
<p>WordRank使用它们词向量的内积对他们之间的关系建模，内积和他们之间的关系是直接成比例的，如果该词和上下文越相关，内积就会越大 .WordRank在语义类比任务上效果最优,论文中提供了对比结果</p>
</li>
</ul>
<h2 id="词向量的应用"><a href="#词向量的应用" class="headerlink" title="词向量的应用"></a>词向量的应用</h2><ul>
<li>计算item之间的相关性,item包括用户,商品,文本等</li>
<li>词的特征扩充 在term weight 里很有用 </li>
<li>作为其它如火如荼的cnn rnn rnn-lstm 系列的初始化输入特征word2vec 算这里面最好的成果了，模型简单，效率高，易调参</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><p><a href="https://blog.csdn.net/itplus/article/details/37969519" target="_blank" rel="noopener">Word2vec中的数学原理详解</a></p>
</li>
<li><p><a href="https://blog.csdn.net/han_xiaoyang/article/details/51648483" target="_blank" rel="noopener">斯坦福cs224d Lecture 2 词向量评价</a></p>
</li>
<li><p><a href="https://radimrehurek.com/gensim/models/word2vec.html" target="_blank" rel="noopener">gensim word2vec</a></p>
</li>
<li><p><a href="https://www.cnblogs.com/pinard/p/7160330.html" target="_blank" rel="noopener">刘建平词向量系列博客</a></p>
</li>
<li><p><a href="https://github.com/Embedding/Chinese-Word-Vectors" target="_blank" rel="noopener">Chinese Word Vectors 中文词向量github</a></p>
</li>
</ul>

      
    </div>
    
    
    

    
      <div>
        <div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center">
    <img id="wechat_subscriber_qcode" src="/uploads/qrcode_for_wechat.jpg" alt="Devin Kuang wechat" style="width: 200px; max-width: 100%;">
    <div>欢迎您扫一扫上面的微信公众号，订阅我的博客！</div>
</div>

      </div>
    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>坚持原创技术分享，您的支持将鼓励我继续创作！</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>Donate</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/images/wechat-reward-image.jpg" alt="Devin Kuang WeChat Pay">
        <p>WeChat Pay</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/images/alipay-reward-image.jpg" alt="Devin Kuang Alipay">
        <p>Alipay</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/编程语言/scala" rel="next" title="scala">
                <i class="fa fa-chevron-left"></i> scala
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
        
<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/uploads/avatar.jpg" alt="Devin Kuang">
          <p class="site-author-name" itemprop="name">Devin Kuang</p>
           
              <p class="site-description motion-element" itemprop="description">关注机器学习和深度学习在搜索, 推荐, 广告和NLP中的运用</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">1</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">1</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/skobekuang" target="_blank" title="Github">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                    
                      Github
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="mailto:devinkuang@qq.com" target="_blank" title="E-mail">
                  
                    <i class="fa fa-fw fa-globe"></i>
                  
                    
                      E-mail
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.zhihu.com/people/kuang-zong-qiang/activities" target="_blank" title="知乎">
                  
                    <i class="fa fa-fw fa-cloud"></i>
                  
                    
                      知乎
                    
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.douban.com/people/devinkuang" target="_blank" title="豆瓣">
                  
                    <i class="fa fa-fw fa-leaf"></i>
                  
                    
                      豆瓣
                    
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              推荐博客
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="https://tech.meituan.com/" title="美团点评技术团队" target="_blank">美团点评技术团队</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.52nlp.cn/" title="52nlp" target="_blank">52nlp</a>
                </li>
              
            </ul>
          </div>
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#中文词向量总结"><span class="nav-number">1.</span> <span class="nav-text">中文词向量总结</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#词向量基础知识"><span class="nav-number">1.1.</span> <span class="nav-text">词向量基础知识</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用gensim训练词向量"><span class="nav-number">1.2.</span> <span class="nav-text">使用gensim训练词向量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#词向量评价"><span class="nav-number">1.3.</span> <span class="nav-text">词向量评价</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#最新研究"><span class="nav-number">1.4.</span> <span class="nav-text">最新研究</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#词向量的应用"><span class="nav-number">1.5.</span> <span class="nav-text">词向量的应用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考资料"><span class="nav-number">1.6.</span> <span class="nav-text">参考资料</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Devin Kuang</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Gemini
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.2"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  

    
      <script id="dsq-count-scr" src="https://devinkaung.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/uncategorized/中文词向量总结';
          this.page.identifier = 'uncategorized/中文词向量总结';
          this.page.title = '中文词向量总结';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://devinkaung.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  








  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("ftghrJsPA56FGzQLKGWKgnT2-gzGzoHsz", "OXlXMWkaHeCrP98JWXUuCAAn");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  

  
  


  

  

</body>

<script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>

</html>
